services:

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse
    ports:
      - 8123:8123
      - 9000:9000
    environment:
      CLICKHOUSE_DB: mydb
      CLICKHOUSE_USER: user
      CLICKHOUSE_PASSWORD: pass

  kafka-to-clickhouse-consumer:
    build: ./kafka-consumer
    container_name: kafka-to-clickhouse-consumer
    ports:
      - 8022:8000
    depends_on:
      - broker-1
      - clickhouse
    environment:
      KAFKA_BROKER: broker-1:19092
      KAFKA_TOPIC: test-topic
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_DB: mydb
      CLICKHOUSE_TABLE: kafka_messages
      CLICKHOUSE_USER: user
      CLICKHOUSE_PASSWORD: pass
    volumes:
      - ./kafka-consumer:/app

  dbt_api:
    build:
      context: ./dbt_project
      dockerfile: Dockerfile
    container_name: dbt_api
    ports:
      - "8000:8000"
    volumes:
      - ./dbt_project:/usr/app
    depends_on:
      - clickhouse
    environment:
      DBT_PROFILES_DIR: /usr/app/.dbt

  broker-1:
    image: apache/kafka:latest
    container_name: broker-1
    ports:
      - 29092:9092
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092,CONTROLLER://:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-1:19092,PLAINTEXT_HOST://localhost:29092'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker-1:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:19092 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  airflow:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow
    restart: always
    depends_on:
      airflow-postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: 'BYICMeuTHySeRi8pvPhBegnYuYD4qQK3fLpJA-7xdrg='
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: 'True'
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
    ports:
      - 8080:8080
    command: >
      bash -c "
        echo 'Waiting for database...' &&
        until pg_isready -h airflow-postgres -p 5432 -U airflow; do
          echo 'Waiting for database...' &&
          sleep 5
        done &&
        echo 'Database is ready!' &&
        airflow db init &&
        echo 'Database initialized!' &&
        airflow users create --username admin --password admin --firstname Air --lastname Flow --role Admin --email admin@example.com &&
        echo 'User created!' &&
        airflow webserver & airflow scheduler & airflow triggerer
      "

  airflow-postgres:
    image: postgres:15
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - 5432:5432
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/dataairflow

  application-postgres:
      image: postgres:15
      container_name: application-postgres
      environment:
        POSTGRES_USER: user
        POSTGRES_PASSWORD: password
        POSTGRES_DB: store
      command: ["postgres", "-c", "wal_level=logical"]
      ports:
        - 5433:5432
      #volumes:
        #- postgres_airflow_data:/var/lib/postgresql/datastore
      healthcheck:          
        test: ["CMD", "pg_isready", "-U", "user", "-d", "store"]
        interval: 5s
        timeout: 5s
        retries: 10
        start_period: 10s

  kafka-connect:
    build: ./kafka-connect
    container_name: kafka-connect
    ports:
      - 8083:8083
    environment:
      BOOTSTRAP_SERVERS: broker-1:19092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect-configs
      OFFSET_STORAGE_TOPIC: connect-offsets
      STATUS_STORAGE_TOPIC: connect-status
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
      KEY_CONVERTER_SCHEMAS_ENABLE: "true"

      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_PLUGIN_PATH: /kafka/connect,/debezium-connector

    depends_on:
      - broker-1
      - schema-registry
      - application-postgres

  schema-registry:
    image: confluentinc/cp-schema-registry:7.7.0
    container_name: schema-registry
    depends_on:
      - broker-1
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker-1:19092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  raport-creator:
    build: ./raport-creator
    container_name: raport-creator
    ports:
      - 8023:8000
    depends_on:
      - broker-1
      - clickhouse
    environment:
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_DB: mydb
      CLICKHOUSE_TABLE: kafka_messages
      CLICKHOUSE_USER: user
      CLICKHOUSE_PASSWORD: pass
    volumes:
      - ./raport-creator:/app

volumes:
  postgres_airflow_data:
  postgres_application_data:

